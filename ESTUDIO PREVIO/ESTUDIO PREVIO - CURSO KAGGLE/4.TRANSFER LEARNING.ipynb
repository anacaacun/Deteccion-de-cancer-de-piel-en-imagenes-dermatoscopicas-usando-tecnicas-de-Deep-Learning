{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clasificar las imágenes en las categorías utilizadas por los modelos originales, pero qué pasaría si hay un nuevo caso de uso y no clasifica las imágenes exactamente de la misma forma que las categorías para el modelo pre-entrenado? \n",
    "\n",
    "Podremos construir un nuevo modelo desde cero para nuestro caso nuevo , pero para obtener buenos resultados necesito miles de fotos con etiquetas para cuales nuestro modelo dirá si son imágenes rurales o no.\n",
    "\n",
    "Esto se llama **transferencia de aprendizaje:** nos dará buenos resultados con mucho menos. Toma lo que un modelo aprende mientras resuelve un nuevo problema.\n",
    "\n",
    "En un aprendizaje profundo, las capas identifican formas simples, las capas posteriores identifican patrones visuales complejos y la última capa hace predicciones, por eso las capas de un modelo pre-entrenado son útiles en nuevas aplicaciones ya que los problemas de visión por computadora involucran patrones visuales similares de bajo nivel, por lo que **reutilizaremos la mayoría del modelo ResNet pre-entrenado** y simplemente se reemplaza la capa final que es identificar características e identificar si una imagen es rural o urbana en función de los resultados de esa capa anterior.\n",
    "\n",
    "Entrada: imágenes\n",
    "ResNet Model: muchas capas, última capa: capa de predicción\n",
    "Salida: Predicción en 1000 categorías\n",
    "\n",
    "Última capa (predicción): contiene información sobre nuestro contenido fotográfico almacenado como una serie de números en un tensor unidimensional (**vector**), que se puede mostrar como una serie de puntos, cada uno de ellos se llama nodo. \n",
    "\n",
    "Una vez que tenemos la última capa (predicción), mantenemos el modelo pre-entrenado y agregamos una nueva capa con dos nodos para poder capturar cómo la foto es urbana o rural.\n",
    "\n",
    "Dibujamos conexiones entre los nodos de la última capa y los nuevos nodos de la nueva predicción para establecer relaciones y cómo podría afectar nuestra medida a cómo de rural es la foto (nueva clasificación). Si se establecen muchas conexiones, realizaremos un entrenamiento para ver qué nodos de la última capa sugieren que una foto es rural o no, y lo mismo para urbana.\n",
    "\n",
    "Paso de capitación: se permite que todas las funciones de una capa, puedan influir o conectarse a una capa de predicción (nueva), cuando esto sucede hablamos de **capa densa**.\n",
    "\n",
    "NOTA: cuando clasificamos algo en solo dos categorías, que podríamos superar con solo un nodo en la salida, en este caso una predicción de lo urbana que sería una foto, tb sería una medida de lo urbana que es una foto si tiene un 80% de probabilidades de ser urbana, es 20% probable de ser rural, pero hemos mantenido dos nodos separados en la capa de salida, usando un nodo separado para cada categoría posible.\n",
    "\n",
    "La capa de salida nos ayudará a hacer la transición a casos en los que queremos predecir con más de 2 categorías. Obtenemos una puntuación por cada categoría y luego aplicamos una función llamada softmax. \n",
    "La función softmax transformará las putuaciones en probabilidades para que todo lo que sea positivo se suma uno que luego podrñiamos trabajar con esas probabilidades.\n",
    "\n",
    "Incorporamos una capa densa para importar que en esta aplicación clasifiquemos las fotos en 2 categorías (urbanas y rurales), las guardamos como clases numéricas y construimos el modelo, un **modelo secuencial (sequential () )** al que podemos agregar capas. Primero **agregamos todo el modelo ResNet 50 pre-entrenado:\n",
    "add(ResNet50 ( include_top=False...**\n",
    "incluimos que es **top = igual a falso**, especificamos que  excluir la capa que hace predicciones en las miles categorías utilizadas. \n",
    "Tb incorporamos un archivo que no incluya pesos para esta última capa **(weights = weights_path)**.\n",
    "**pooling = 'avg'** dice que si tuviéramos canales adicionales en nuestro tensor al final de este paso, desea contenerlos en un tensor 1d tomando un promedio a través de los canales.\n",
    "\n",
    "**my_new_model.add (Dense( num classes, activation = 'softmax'))**: agregar capas densas para hacer predicciones especificamos el número de nodos y que queremos aplicar la función softmax para poder convertirla en probabilidades\n",
    "\n",
    "**my_new_model.layers[0].trainable = False**: le dice a las decenas que no entren en la primera capa, que es el modelo ResNet50 que ya fue pre-entrenado previamente.\n",
    "\n",
    "- Comando de compilación: le dice al tensorflow cómo actualizar las relaciones en las conexiones densas. Cuando estamos entrenando con nuestros datos tenemos un medida de pérdida que queremos minimizar\n",
    "\n",
    "Usamos un algoritmo llamado **descenso de gradiente estocástico** para minimizar esta pérdida (entropía):\n",
    "\n",
    "**my_new_model.compile ( optimizer = 'sgd', loss = 'categorical_crossentropy', metrics=['accuracy'])**\n",
    " No solo trata la entropía sino que tb informa de la métrica de precisión (accuracy), que es qué fracción de las fracciones fueron correctas\n",
    "\n",
    "Dividimos los datos sin procesar en un directorio de datos de entrenamiento y uno de datos de validación. Dentro de cada uno tenemos un subdirectorio para el urbano y otro para el rural.\n",
    "Hay 2 pasos para usar el generador de datos de imagen:\n",
    "\n",
    "1. Generamos cualquier objeto en abstracto. Le decimos que queremos aplicar la función de preprocesamiento ResNet. \n",
    "\n",
    "from tensoflow.python.keras.preprocesing.image import ImageDataGnerator \n",
    "\n",
    "data_generator = ImageDataGenerator(preprocesing_function = preprocess_input)\n",
    "\n",
    "Luego usamos un comando de flujo desde el directorio, de forma que le decimos en qué directorio están los datos, qué tamaño de imagen queremos, cuántas imágenes a la vez (batch) y que estamos clasificando los datos en distintas categorías (class_mode = 'categorical', y tb el tamaño del lote\n",
    "\n",
    "**date_generator.flow_from_directory(....\n",
    "\n",
    "Hacemos esto para el directorio de entrenamiento y de validación.\n",
    "\n",
    "Nos ajustamos al modelo, le decimos la capacitación a través de un generador capacitado para leer 12 imágenes a la vez ( 6 pasos de 12 imágenes, ya que tenemos 72 imágenes).\n",
    "\n",
    "El generador de validación lee 20 imágenes a la vez y como tenemos 20 imágenes \n",
    "\n",
    "Calculando... en 6 pasos está hecho, se obtiene el 79% de los datos de entrenamiento y el 95% de correctos en los de validación.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CÓDIGO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-44befc888468>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.applications import ResNet50\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "num_classes = 2\n",
    "resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "my_new_model = Sequential()\n",
    "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
    "my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Say not to train first layer (ResNet) model. It is already trained\n",
    "my_new_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPILE MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIT MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 224\n",
    "data_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "        '../input/urban-and-rural-photos/rural_and_urban_photos/train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=24,\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "        '../input/urban-and-rural-photos/rural_and_urban_photos/val',\n",
    "        target_size=(image_size, image_size),\n",
    "        class_mode='categorical')\n",
    "\n",
    "my_new_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=3,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como steps_per_epoch = 3, quiere decir que como el generador de entrenamiento puede leer hasta 24 imágenes a la vez, y nuestro conjunto es de 72, con repetirlo 3 veces ya se completaría el conjunto total de imágenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota sobre los resultados:\n",
    "La precisión de la validación impresa puede ser significativamente mejor que la precisión del entrenamiento en esta etapa. Esto puede ser desconcertante al principio.\n",
    "\n",
    "Ocurre porque la precisión del entrenamiento se calculó en varios puntos a medida que la red mejoraba (los números en las circunvoluciones se actualizaban para hacer que el modelo fuera más preciso). La red era inexacta cuando el modelo vio las primeras imágenes de entrenamiento, ya que los pesos aún no se habían entrenado / mejorado mucho. Esos primeros resultados de entrenamiento se promediaron en la medida anterior.\n",
    "\n",
    "Las pérdidas de validación y las medidas de precisión se calcularon después de que el modelo revisó todos los datos. Por lo tanto, la red había sido completamente entrenada cuando se calcularon estos puntajes.\n",
    "\n",
    "Este no es un problema grave en la práctica, y tendemos a no preocuparnos por eso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJERCICIOS**\n",
    "\n",
    "El camarógrafo que filmó nuestros videos de aprendizaje profundo mencionó un problema que podemos resolver con el aprendizaje profundo.\n",
    "\n",
    "Ofrece un servicio que escanea fotografías para almacenarlas digitalmente. Él usa una máquina que escanea rápidamente muchas fotos. Pero dependiendo de la orientación de la foto original, muchas imágenes se digitalizan de lado. Los arregla manualmente, mirando cada foto para determinar cuáles rotar.\n",
    "\n",
    "En este ejercicio, **creará un modelo que distingue qué fotos están de lado y cuáles están en posición vertical,** de modo que una aplicación podría rotar automáticamente cada imagen si es necesario.\n",
    "\n",
    "Si iba a vender este servicio comercialmente, podría usar un gran conjunto de datos para entrenar el modelo. Pero tendrá un gran éxito incluso con un pequeño conjunto de datos. Trabajará con un pequeño conjunto de datos de imágenes de perros, la mitad de los cuales se giran hacia los lados.\n",
    "\n",
    "Especificar y compilar el modelo tiene el mismo aspecto que en el ejemplo que ha visto. Pero deberá realizar algunos cambios para adaptarse al modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ESPECIFICO EL MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "\n",
    "num_classes = 2\n",
    "resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "my_new_model = Sequential()\n",
    "my_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\n",
    "my_new_model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Indicate whether the first layer should be trained/changed or not.\n",
    "my_new_model.layers[0].trainable = False\n",
    "\n",
    "# Check your answer\n",
    "step_1.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.COMPILO EL MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_new_model.compile(optimizer='sgd', \n",
    "                     loss='categorical_crossentropy', \n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eso corrió casi instantáneamente. Los modelos de aprendizaje profundo tienen la reputación de ser computacionalmente exigentes. ¿Por qué corrió eso tan rápido?\n",
    "\n",
    "**RESPUESTA: El modelo de compilación no cambia los valores en ninguna convolución. De hecho, su modelo aún no ha recibido una discusión con datos. La compilación especifica cómo su modelo realizará actualizaciones en un paso posterior en el que reciba datos. Esa es la parte que llevará más tiempo.**\n",
    "\n",
    "Este paso tiene 3 argumentos: optimizador, pérdida y métricas.\n",
    "\n",
    "Qué argumento puede afectar al grado de precisión? \n",
    "\n",
    "**RESPUESTA:**\n",
    "- El optimizador (optimizer) determina cómo determinamos los valores numéricos que componen el modelo. Por lo tanto, puede afectar el modelo resultante y las predicciones.\n",
    "- La pérdida (loss) determina qué objetivo optimizamos al determinar los valores numéricos en el modelo. Por lo tanto, puede afectar el modelo resultante y las predicciones.\n",
    "- La métrica (metrics) determina solo lo que imprimimos mientras se construye el modelo, pero no afecta el modelo en sí.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. FIT MODEL**\n",
    "\n",
    "Tenemos 220 imágenes de entrenamiento y 217 de validación. \n",
    "El generador de entrenamiento puede leer 10 imágenes a la vez. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_size = 224\n",
    "data_generator = ImageDataGenerator(preprocess_input)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "                                        directory='../input/dogs-gone-sideways/images/train',\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        batch_size=10,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "                                        directory='../input/dogs-gone-sideways/images/val',\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "# fit_stats below saves some statistics describing how model fitting went\n",
    "# the key role of the following line is how it changes my_new_model by fitting to data\n",
    "fit_stats = my_new_model.fit_generator(train_generator,\n",
    "                                       steps_per_epoch=22,\n",
    "                                       validation_data=validation_generator,\n",
    "                                       validation_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTADOS: \n",
    "    Precisión: 70%\n",
    "    Nivel de pérdida: 17%\n",
    "    Precisión del generador de validación: 96%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
