{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta ahora hemos utilizado la transferencia de aprendizaje. \n",
    "Deep Learning es excelente a la hora de poder construir rápidamente modelos precisos, incluso con relativamente pocos datos, pero el aprendizaje de transferencia no es necesario en datos grandes  y solo funciona cuando su caso de uso tiene patrones visuales similares a los datos utilizados en el modelo preentrenado, por ejemplo: un modelo preentrenado basado en las fotos cotidianas non funcionará bien para aplicaciones de fotografías de satelites o para fotos medicas de una maquina de resonancia, asi que si quieres ser versatil con profundidad hay que aprender a construir modelos.\n",
    "\n",
    "Cargamos los datos (fotos) del nido M para almacenar todas las imágenes en una sola:\n",
    "**train_file = \"--.train.csv\"**\n",
    "**raw_data = pd.read_csv(train_file)**\n",
    "Cada imagen se representa como una fila del CSV, la primera columna tiene una etiqueta en estos datos, la etiqueta dice qué digito se muestra en cada fila del CSV. \n",
    "El resto de columnas representan las intensidades de los pixeles.\n",
    "\n",
    "Preparación de los datos para extraer etiquetas y remodelas la intensidad de los píxeles:\n",
    "\n",
    "**img_rows, img_cols = 28,28** #cuadricula\n",
    "**num_classes = 10**\n",
    "\n",
    "def data_prep(raw):\n",
    "    out_y = **keras.utils.to_categorical(raw.label, mum_classes)** #función categórica suministramos la etiqueta de fila variable objetivo, así como el número de valores diferentes (num-classes), que devuelve 10 valores objetivo con 10 columnas binarias separadas\n",
    "\n",
    "**num_images = raw.shape[0]**\n",
    "\n",
    "x_as_array = **raw.values[:,1:]** #intesidades de pixeles , nos da los datos como una matriz numpy, usamos indexación para tomar todo después de la primera columna (xq la primera columna era la etiqueta) \n",
    "\n",
    "x_shaped_array = **x_as_array.reshape(num_images, img_rows,img_cols,1)** #cambiamos la forma de los datos a una matriz 4d que está indexado por el número de imagen, número de fila, número de columna, y como esta en escala de grises y no en color solo habrá 1 canal .\n",
    "\n",
    "out_x = **x_shaped_array / 255** #divide los valores entre 255 para que todos los datos estén entre 0 y 1, esto mejora la optimización con los parámetros predeterminados. \n",
    "\n",
    "**return out_x, out_y**\n",
    "\n",
    "Para el optimizador de átomos, esta función nos dio una serie de predictores que llamaré X y una matriz del objetivo que llamaré Y y construiremos nuestro modelo:\n",
    "\n",
    "**x,y = data_prep(raw_data)**\n",
    "\n",
    "En este modelo destacamos que la primera capa es convolucional 2d:\n",
    "**model.add(Conv2D(20,kernel_size = (3,3), activation='relu,input_shape=(img_rows,img_cols,1)))**\n",
    "\n",
    "También agregamos una capa convolucional antes del aplanamiento:\n",
    "**model.add(Conv2D(20,kernel_size=(3,3),activation='relu))**\n",
    "\n",
    "Argumentos de estas capas convolucionales:\n",
    "Número de circunvoluciones o filtros que se incluirán en esa capa.\n",
    "El tamaño y pixeles de las convoluciones que se llama tamaño del nucleo.\n",
    "Funcion de activacion: para la primera capa tengo que especificar la forma de cada imagen (shape), pero no para las otras capas.\n",
    "\n",
    "En este caso se usaron 2 capas convolucionales, pero se podrian haber usado más.\n",
    "\n",
    "Capa aplanada: \n",
    "**model.add(Flatten())** para convertir las salidas de las capas anteriores en una representacion 1s para cada imagen.\n",
    "\n",
    "Los modelos generalmente funcionan mejor si se agrega una capa densa entre los planos y una capa de predicción final, así que agregamos una capa densa con 128 nodos:\n",
    "**model.add(Dense(128, activation='relu'))**\n",
    "\n",
    "Capa de salida:\n",
    "**model.add(Dense(num_classes, activation='softmax'))**\n",
    "\n",
    "Luego compilamos ( **función compile**) y lo ajustamos (**funcion fit**) en ella proporciono los predictores x y el objetivo, especifico el tamaño del lote (**batch_size**) y varias epocas (**epochs**) y finalmente la puntuación de validación (**validation_split=0.2**), para decir que el 20% de los datos deben reservarse para la validación, dejando el 80% para la capacitación.\n",
    "\n",
    "Al ejecutar esto, puedo ver la precisión de 10% entrenando aproximadamente el 98% bastante rápido,.\n",
    "\n",
    "Si aumentamos el numero de capas o el numero de convoluciones en una capa, aumentas la capacidad del modelo para adaptarse a los datos de entrenamiento. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n",
    "\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def data_prep(raw):\n",
    "    out_y = keras.utils.to_categorical(raw.label, num_classes)\n",
    "\n",
    "    num_images = raw.shape[0]\n",
    "    x_as_array = raw.values[:,1:]\n",
    "    x_shaped_array = x_as_array.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = x_shaped_array / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "train_file = \"../input/digit-recognizer/train.csv\"\n",
    "raw_data = pd.read_csv(train_file)\n",
    "\n",
    "x, y = data_prep(raw_data)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))\n",
    "model.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=2,\n",
    "          validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EJERCICIO**\n",
    "Has visto cómo construir un modelo desde cero para identificar dígitos escritos a mano. Ahora construirá un modelo para identificar diferentes tipos de ropa. Para hacer modelos que entrenan rápidamente, trabajaremos con imágenes muy pequeñas (de baja resolución).\n",
    "\n",
    "Como ejemplo, su modelo tomará imágenes como esta y lo identificará como un zapato:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PREPARACIÓN DE LOS DATOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "def prep_data(raw):\n",
    "    y = raw[:, 0]\n",
    "    out_y = keras.utils.to_categorical(y, num_classes)\n",
    "    \n",
    "    x = raw[:,1:]\n",
    "    num_images = raw.shape[0]\n",
    "    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n",
    "    out_x = out_x / 255\n",
    "    return out_x, out_y\n",
    "\n",
    "fashion_file = \"../input/fashionmnist/fashion-mnist_train.csv\"\n",
    "fashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\n",
    "x, y = prep_data(fashion_data)\n",
    "\n",
    "# Set up code checking\n",
    "from learntools.core import binder\n",
    "binder.bind(globals())\n",
    "from learntools.deep_learning.exercise_7 import *\n",
    "print(\"Setup Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)START THE MODEL**\n",
    "Create a `Sequential` model called `fashion_model`. Don't add layers yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Add the first layer**\n",
    "Agregue la primera capa Conv2D a fashion_model. Debe tener 12 filtros, un kernel_size de 3 y la función de activación relu. La primera capa siempre requiere que especifique input_shape. Hemos guardado el número de filas y columnas en las variables img_rows e img_cols respectivamente, por lo que la forma de entrada en este caso es (img_rows, img_cols, 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.add(Conv2D(12, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=(img_rows, img_cols, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Agregue las capas restantes**\n",
    "Agregue 2 más convolucionales (capas Conv2D) con 20 filtros cada uno, activación 'relu' y un tamaño de núcleo de 3. Siga eso con una capa Flatten, y luego una capa Densa con 100 neuronas.\n",
    "\n",
    "Agregue su capa de predicción a fashion_model. Esta es una capa densa. Ya tenemos una variable llamada num_classes. Use esta variable cuando especifique el número de nodos en esta capa. La activación debe ser softmax (o tendrá problemas más adelante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "fashion_model.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "fashion_model.add(Conv2D(20, kernel_size=(3, 3), activation='relu'))\n",
    "fashion_model.add(Flatten())\n",
    "fashion_model.add(Dense(100, activation='relu'))\n",
    "fashion_model.add(Dense(num_classes, activation='softmax'))\n",
    "# Check your answer\n",
    "q_3.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**COMPILAMOS EL MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to compile the model in this cell\n",
    "fashion_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AJUSTAMOS EL MODELO**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model.fit(x, y,\n",
    "          batch_size=100,\n",
    "          epochs=4,\n",
    "          validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
