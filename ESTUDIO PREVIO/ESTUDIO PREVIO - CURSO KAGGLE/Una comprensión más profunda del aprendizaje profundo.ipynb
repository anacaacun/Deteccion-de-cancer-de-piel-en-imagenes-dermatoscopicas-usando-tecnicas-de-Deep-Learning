{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Una comprensión más profunda del aprendizaje profundo**\n",
    "Objetivos: comprender cómo usamos un descenso de gradiente para establecer valores numéricos en capas densas y convolucionales,así como la forma en la que los argumentos como el tamaño del lote y el nº de épocas afectan a la capacitación de este modelo.\n",
    "\n",
    "Comenzamos con un ejemplo usando capas densas: imagina que queremos evaluar el riesgo de alguien de desarrollar diabetes en el próximo año. \n",
    "Tenemos los siguientes datos: peso, edad, medición de azúcar en sangre, por tanto podríamos dibujar una \n",
    "-capa **(input layer)** con un nodo para cada una de las 3 variables: edad, peso, azucar en sangre; ya que esta capa representa datos sin procesar \n",
    "Vamos a conectar la capa de entrada directamente con la capa de predicción: **(prediction layer)**: dos nodos : diabetes(si), diabetes(no).\n",
    "Las conectamos como una capa densa: cada nodo de la entrada está conectado a cada nodo de salida. Esta conexión tendrá un número asociado con él, estos números se llaman pesos. Si completamos los datos para una persona, podemos calcular los valores en la próxima: proceso de propagación directa. \n",
    "La función softmax convierte estos pesos en prueba de probabilidades.\n",
    "Las capas entre la entrada y la salida se llaman ocultas **(hidden layer)**, el proceso de propagación hacia adelante sigue siendo el mismo.\n",
    "En la práctica se aplicará alguna función no lineal en cada nodo en las capas ocultas, incluida una no lineal.\n",
    "La función ayuda al modelo a capturar no linealidades e impactos de interacción entre las variables. La función más común para aplicar es el rel o la función de activación lineal rectificada. \n",
    "\n",
    "Los pesos cambian las predicciones finales, por lo que los buenos pesos son la clave de las buenas predicciones. \n",
    "\n",
    "Hay 3 conceptos para entender cómo el modelo es bueno. \n",
    "\n",
    "Los pesos son funciones de pérdida que crean descenso y una propagación hacia atrás.La función de perdida y el descenso de gradiente se muestran en nuestro código como argumentos a la función de compilación antes de ajustar nuestro modelo.\n",
    "\n",
    "La función de pérdida mide qué tan buenas son las predicciones del modelo, los argumentos son los valores reales del objetivo que tb queríamos predecir.\n",
    "\n",
    "**loss = f(actual, predicted)**\n",
    "\n",
    "Si esta función da un valor bajo: mejor, los valores pronosticados están cerca del valor real.\n",
    "Si la f.pérdida da un valor alto: las predicciones están lejos.\n",
    "\n",
    "Para que la función de pérdida en cualquier conjunto de datos tb cambia si cambiamos los pesos de los modelos, esto es clave para nuestro modelo.\n",
    "A la hora del procedimiento de optimización de descenso de gradiente y descenso de gradiente estocástico se ralice bien.Solían lanzar un descenso de gradiente para establecer los pesos que minimizan nuestra pérdida. **Recordemos que los pesos afectan a nuestras predicciones y por tanto, a la función de pérdida.**\n",
    "\n",
    "**analogía grandiente de descenso**: vas cuesta abajo, y das un paso en esa dirección y otro y otro hasta que no puedes bajar más.\n",
    "\n",
    "Como paso esto a la práctica? miro los datos, veo qué puedo cambiar la forma de obtener un poco baja la función de pérdida y luego cambio el peso ligeramente en esa dirección.\n",
    "Repito lo mismo para mejorar el peso ligeramente de nuevo, \n",
    "\n",
    "Tamaño del lote = número de imágenes de nuestro dataset, establecemos este tamaño como argumento de aprendizaje de transferencia.\n",
    "Programamos un lote pequeño y luego el siguiente hasta que hayamos usado todos nuestros datos.\n",
    "\n",
    "A través de los datos, se llama una época que mejoramos gradualmente las ponderaciones para varias épocas, de modo que cada imagen o un punto de datos se utilizaría para mejorar los pesos. \n",
    "\n",
    "**propagación** = proceso en el cual descubrimos cómo cambiamos los pesos en cada paso del descenso gradual. \n",
    "\n",
    "**EJEMPLO**: \n",
    "Queremos saber si un valor tiene diabetes.\n",
    "Vamos a ver cómo cambiar los pesos para hacer que el modelo sea más preciso para un lote = 1 (un valor), y digamos que el valor real del objetivo de predicción para esta persona es que no tenía diabetes.\n",
    "\n",
    "Si predijimos que no tenía diabetes, nuestra función de pérdida tendría un valor bajo con poca capacidad de mejorar. Ademas, si predijéramos que probablemente tendrían diabetes, tendríamos mucho espacio para mejorar, pero  \n",
    "¿COMO CAMBIAMOS LOS PESOS PARA MEJORAR?\n",
    "Retrocedemos una capa, ese nodo alimenta en ese valor de predicción que tuvo un valor positivo durante la propagación hacia adelante, es un peso que conecta ese nodo a la salida para saber cuánto más alto de esa manera es mas probable que predijamos que no, \n",
    "eso significa que el modelo que tiene un mejor función de pérdida para esa persona para que podamos aumentar el valor de ese peso rojo y eso mejora la funcion de persidad cuanto mas la aumentamos.\n",
    "\n",
    "El proceso de cambiar los pesos para una mejor predicción es lo que se llama tasa de aprendizaje.\n",
    "De esta forma nuestro modelo (clasificador) podrá mejorar en cuanto a predicciones o no. \n",
    "\n",
    "Esto se aplica en el **fit_generator**:\n",
    "\n",
    "my_new_model.fit_generator(train_generator, steps_per_epoch = 6, validation_data = validation_generator, validation_steps = 1, optimizer= \"adam\")\n",
    "\n",
    "- Se puede usar el optimizador de argumentos = \"adam\" para una variación especial de descenso de gradiente que calcula automáticamente la mejor tasa de aprendizaje a lo largo del proceso de descenso de gradiente.\n",
    "\n",
    "Funciona igual con capas densas que con capas convolucionales.\n",
    "**Conclusión: impacto en la predicción del modelo, hacer pequeñas actualizaciones en los pesos tratando de encontrar el punto mas bajo de nuestra función de pérdida.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
